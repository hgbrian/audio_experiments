{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import lasagne\n",
    "import time\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import os.path\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "from lasagne.utils import floatX\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# VGG-19, 19-layer model from the paper:\n",
    "# \"Very Deep Convolutional Networks for Large-Scale Image Recognition\"\n",
    "# Original source: https://gist.github.com/ksimonyan/3785162f95cd2d5fee77\n",
    "# License: non-commercial use only\n",
    "\n",
    "from lasagne.layers import InputLayer, DenseLayer, NonlinearityLayer\n",
    "#from lasagne.layers.dnn import Conv2DDNNLayer as ConvLayer\n",
    "from lasagne.layers import Conv2DLayer as ConvLayer\n",
    "from lasagne.layers import Pool2DLayer as PoolLayer # ORIG\n",
    "#from lasagne.layers import MaxPool2DLayer as PoolLayer\n",
    "from lasagne.nonlinearities import softmax\n",
    "\n",
    "IMAGE_W = 512\n",
    "if \"NS_IMAGE_W\" in os.environ: IMAGE_W = int(os.environ[\"NS_IMAGE_W\"])\n",
    "\n",
    "# Note: tweaked to use average pooling instead of maxpooling\n",
    "def build_model():\n",
    "    net = {}\n",
    "    net['input'] = InputLayer((1, 3, IMAGE_W, IMAGE_W))\n",
    "    net['conv1_1'] = ConvLayer(net['input'], 64, 3, pad=1)\n",
    "    net['conv1_2'] = ConvLayer(net['conv1_1'], 64, 3, pad=1)\n",
    "    net['pool1'] = PoolLayer(net['conv1_2'], 2, mode='average_exc_pad')\n",
    "    net['conv2_1'] = ConvLayer(net['pool1'], 128, 3, pad=1)\n",
    "    net['conv2_2'] = ConvLayer(net['conv2_1'], 128, 3, pad=1)\n",
    "    net['pool2'] = PoolLayer(net['conv2_2'], 2, mode='average_exc_pad')\n",
    "    net['conv3_1'] = ConvLayer(net['pool2'], 256, 3, pad=1)\n",
    "    net['conv3_2'] = ConvLayer(net['conv3_1'], 256, 3, pad=1)\n",
    "    net['conv3_3'] = ConvLayer(net['conv3_2'], 256, 3, pad=1)\n",
    "    net['conv3_4'] = ConvLayer(net['conv3_3'], 256, 3, pad=1)\n",
    "    net['pool3'] = PoolLayer(net['conv3_4'], 2, mode='average_exc_pad')\n",
    "    net['conv4_1'] = ConvLayer(net['pool3'], 512, 3, pad=1)\n",
    "    net['conv4_2'] = ConvLayer(net['conv4_1'], 512, 3, pad=1)\n",
    "    net['conv4_3'] = ConvLayer(net['conv4_2'], 512, 3, pad=1)\n",
    "    net['conv4_4'] = ConvLayer(net['conv4_3'], 512, 3, pad=1)\n",
    "    net['pool4'] = PoolLayer(net['conv4_4'], 2, mode='average_exc_pad')\n",
    "    net['conv5_1'] = ConvLayer(net['pool4'], 512, 3, pad=1)\n",
    "    net['conv5_2'] = ConvLayer(net['conv5_1'], 512, 3, pad=1)\n",
    "    net['conv5_3'] = ConvLayer(net['conv5_2'], 512, 3, pad=1)\n",
    "    net['conv5_4'] = ConvLayer(net['conv5_3'], 512, 3, pad=1)\n",
    "    net['pool5'] = PoolLayer(net['conv5_4'], 2, mode='average_exc_pad')\n",
    "\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "net info\n",
      "--------\n",
      "W.shape (64, 3, 3, 3) b.shape (64,)\n",
      "\n",
      "conv_lasagne\n",
      "---------\n",
      "conv_lasagne.shape (1, 64, 16, 16)\n",
      "conv_lasagne[0,2,1] [ 0.00126734  0.00186376  0.00186678  0.0018698   0.00187282  0.00187584\n",
      "  0.00187886  0.00188188  0.0018849   0.00188792  0.00189094  0.00189396\n",
      "  0.00189698  0.0019      0.00190302  0.00318206]\n",
      "\n",
      "conv_T\n",
      "------\n",
      "conv_T.shape (1, 64, 16, 16)\n",
      "conv_T[0,2,1] [ 0.00126734  0.00186376  0.00186678  0.0018698   0.00187282  0.00187584\n",
      "  0.00187886  0.00188188  0.0018849   0.00188792  0.00189094  0.00189396\n",
      "  0.00189698  0.0019      0.00190302  0.00318206]\n",
      "\n",
      "conv_GEMM\n",
      "---------\n",
      "test_photo_im2col.shape (16, 16, 3, 3, 3)\n",
      "test_photo_gemm.shape (256, 27)\n",
      "params_gemm.shape (27, 64)\n",
      "conv_GEMM[0,2,1] [ 0.00126734  0.00186376  0.00186678  0.0018698   0.00187282  0.00187584\n",
      "  0.00187886  0.00188188  0.0018849   0.00188792  0.00189094  0.00189396\n",
      "  0.00189698  0.0019      0.00190302  0.00318206]\n",
      "\n",
      "assert np.allclose(conv_T, conv_lasagne) True\n",
      "assert np.allclose(conv_GEMM, conv_lasagne) True\n"
     ]
    }
   ],
   "source": [
    "def im_to_col(im, psize, n_channels=3, pad=None):\n",
    "    \"\"\"Similar to MATLAB's im2col function.\n",
    "\n",
    "    Args:\n",
    "    im - a Theano tensor3, of the form <n_channels, height, width>.\n",
    "    psize - an int specifying the (square) block size to use\n",
    "    n_channels - the number of channels in im\n",
    "\n",
    "    Returns: a 5-tensor of the form <patch_id_i, patch_id_j, n_channels, psize,\n",
    "           psize>.\n",
    "    \"\"\"\n",
    "    assert im.ndim == 3, \"im must have dimension 3.\"\n",
    "    \n",
    "    if pad is not None:\n",
    "        C = 0\n",
    "        im = np.pad(im, [(0,0),(pad,pad),(pad,pad)], 'constant', constant_values=C)\n",
    "        assert im.shape[0] == 3\n",
    "    \n",
    "    DEFAULT = False\n",
    "    if DEFAULT:\n",
    "        im = im[:, ::-1, ::-1]\n",
    "    \n",
    "    res = T.zeros((n_channels, psize * psize, im.shape[1] - psize + 1,\n",
    "                  im.shape[2] - psize + 1))\n",
    "    filts = T.reshape(T.eye(psize * psize, psize * psize),\n",
    "                      (psize * psize, psize, psize))\n",
    "    filts = T.shape_padleft(filts).dimshuffle((1, 0, 2, 3))\n",
    "\n",
    "    for i in xrange(n_channels):\n",
    "        cur_slice = T.shape_padleft(im[i], n_ones=2)\n",
    "        res = T.set_subtensor(res[i], T.nnet.conv.conv2d(cur_slice, filts)[0])\n",
    "\n",
    "    return res.dimshuffle((0, 2, 3, 1)).reshape(\n",
    "      (n_channels, im.shape[1] - psize + 1, im.shape[2] - psize + 1,\n",
    "       psize, psize)).dimshuffle((1, 2, 0, 3, 4))\n",
    "\n",
    "#\n",
    "# Set up net, initialize weights.\n",
    "# 16x16 is the smallest acceptable image size\n",
    "# There are 64 filters/kern\n",
    "#\n",
    "NUM_K = 64\n",
    "IMAGE_W = 16\n",
    "net = build_model()\n",
    "values = pickle.load(open('vgg19_normalized.pkl'))['param values']    \n",
    "lasagne.layers.set_all_param_values(net['pool5'], values)\n",
    "\n",
    "#\n",
    "# https://github.com/Lasagne/Recipes/issues/9\n",
    "# Flip filter when using Conv2D instead of Conv2DDNNLayer\n",
    "# Depending on how the net was trained you flip, or not\n",
    "# Not flipping is not a true convolution but is a bit faster, hence it's used for DNN\n",
    "#\n",
    "FLIP_FILTER = True\n",
    "if FLIP_FILTER:\n",
    "    for k in net:\n",
    "        layer = net[k]\n",
    "        if k.startswith('conv'):\n",
    "            layer.W.set_value(np.asarray(layer.W.get_value())[:,:,::-1,::-1])\n",
    "\n",
    "\n",
    "#\n",
    "# Get net weights and set net bias to 0\n",
    "#\n",
    "W, b = lasagne.layers.get_all_param_values(net['conv1_1'])\n",
    "print \"\\nnet info\\n\",\"--------\"\n",
    "print \"W.shape\", W.shape, \"b.shape\", b.shape\n",
    "\n",
    "#\n",
    "# Fake photo, ones or arange\n",
    "#\n",
    "test_photo = np.ones( (1,3,IMAGE_W,IMAGE_W), np.float32 )\n",
    "test_photo[0,:,0,0] = 2.0\n",
    "test_photo[0,:,1,1] = 3.0\n",
    "test_photo = np.arange(1*3*IMAGE_W*IMAGE_W).reshape((1,3,IMAGE_W,IMAGE_W)).astype(np.float32) / 10000.\n",
    "\n",
    "#\n",
    "# 1. Calculate the real answer with lasagne\n",
    "#\n",
    "# deterministic=True is unnecessary for this layer (no dropout before)\n",
    "conv_lasagne = lasagne.layers.get_output(net['conv1_1'], test_photo, deterministic=True).eval()\n",
    "\n",
    "#\n",
    "# Lagagne output\n",
    "#\n",
    "print \"\\nconv_lasagne\\n\",\"---------\"\n",
    "print \"conv_lasagne.shape\", conv_lasagne.shape\n",
    "print \"conv_lasagne[0,2,1]\", conv_lasagne[0,2,1]\n",
    "\n",
    "\n",
    "#\n",
    "# 2. Test theano conv2d\n",
    "# \n",
    "# http://lasagne.readthedocs.org/en/latest/modules/layers/conv.html\n",
    "# Theanoâ€™s underlying convolution (theano.tensor.nnet.conv.conv2d()) only supports pad=0 and pad='full'. \n",
    "# This layer emulates other modes by cropping a full convolution or explicitly padding the input with zeros.\n",
    "# Alternative to add_pad is to use border_mode=\"full\" and\n",
    "# crop_x = 3 // 2; crop_y = 3 // 2; conv_T = conv_T[:, :, crop_x:-crop_x or None, crop_y:-crop_y or None]\n",
    "#\n",
    "def add_pad(im, pad=1, const=0):\n",
    "    return np.pad(im, [(0,0),(0,0),(pad,pad),(pad,pad)], 'constant', constant_values=const)\n",
    "\n",
    "conv_T = T.nnet.conv.conv2d(add_pad(test_photo), W, border_mode='valid', subsample=(1,1)).eval()\n",
    "\n",
    "# Add bias and apply rectifier\n",
    "# (Theano/lasagne version: activation = conved + self.b.dimshuffle('x', 0, 'x', 'x'))\n",
    "conv_T += b[None,:,None,None]\n",
    "conv_T[conv_T<0] = 0\n",
    "\n",
    "print \"\\nconv_T\\n\",\"------\"\n",
    "print \"conv_T.shape\", conv_T.shape\n",
    "print \"conv_T[0,2,1]\", conv_T[0,2,1]\n",
    "\n",
    "\n",
    "#\n",
    "# 3. GEMM\n",
    "#\n",
    "\n",
    "#\n",
    "# Each row is a \"patch\" of size 3x3x3\n",
    "# http://petewarden.com/2015/04/20/why-gemm-is-at-the-heart-of-deep-learning/\n",
    "#\n",
    "test_photo_im2col = im_to_col(test_photo[0], 3, pad=1).eval()\n",
    "test_photo_gemm = test_photo_im2col.reshape(IMAGE_W*IMAGE_W,3*3*3)\n",
    "\n",
    "print \"\\nconv_GEMM\\n\", \"---------\"\n",
    "print \"test_photo_im2col.shape\", test_photo_im2col.shape\n",
    "print \"test_photo_gemm.shape\", test_photo_gemm.shape\n",
    "print \"params_gemm.shape\", params_gemm.shape\n",
    "\n",
    "#\n",
    "# reshape weights to len(patch) rows * num_kernels cols\n",
    "# 64x3x3x3\n",
    "#\n",
    "params_gemm = W.reshape(NUM_K,3*3*3).T\n",
    "\n",
    "#\n",
    "# Do mega dot product (GEMM)\n",
    "#\n",
    "conv_GEMM = np.dot(test_photo_gemm, params_gemm) \n",
    "conv_GEMM = np.array([conv_GEMM.T.reshape(NUM_K,IMAGE_W,IMAGE_W)])\n",
    "\n",
    "#\n",
    "# Add bias and apply rectifier\n",
    "#\n",
    "conv_GEMM += b[None,:,None,None]\n",
    "conv_GEMM[conv_GEMM<0] = 0 # rectify\n",
    "\n",
    "#\n",
    "# 4. Results\n",
    "#\n",
    "print \"conv_GEMM[0,2,1]\", result_end[0,2,1]\n",
    "print\n",
    "print \"assert np.allclose(conv_T, conv_lasagne) True\"\n",
    "assert np.allclose(conv_T, conv_lasagne)\n",
    "print \"assert np.allclose(conv_GEMM, conv_lasagne) True\"\n",
    "assert np.allclose(conv_GEMM, conv_lasagne)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
